{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "I'll take a look at text data and turn it into quantifiable measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From randomly sampled tweets, I decided to do at least the following: \n",
    "\n",
    "1. find any links and remove them (e.g. bit.ly/g03MZB)\n",
    "2. `@mention`, `{link}`\n",
    "Create a feature that shows how many of these exists, but remove them from tokenization.\n",
    "3. `[\\w+]` seems to be emoji or pics/videos. keep them as is (with brackets) \n",
    "3. word after # should be treated as a separate word than the same word without #, also count how many tags\n",
    "4. `?&quot;`, `$amp;`, `�` should be removed.\n",
    "5. ! and ? might be important to keep. count how many. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('DATA/X_train.csv', index_col=0)\n",
    "X_val = pd.read_csv('DATA/X_val.csv', index_col=0)\n",
    "X_test = pd.read_csv('DATA/X_test.csv', index_col=0)\n",
    "y_train = pd.read_csv('DATA/y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitalized\n",
    "Sometimes capitalized letters indicate stronger sentiment. Let's see proportionally how many are capitalized, before we make everything lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_upper(str_):\n",
    "    return sum([x.isupper() for x in str_])/len(str_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find links and turn them into {link}\n",
    "def replace_links(str_):\n",
    "    p = '((http\\w*:\\/\\/)?(www\\.\\w+)?(\\w+\\.(com|co|ly|ch|org|net)+)(\\/\\w+)?)'\n",
    "    return re.sub(p, '{link}', str_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count \n",
    "Count how many mentions, tags, links, '!', '?', '.' happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times specific expression occurs.\n",
    "def count_exp(str_, exp):\n",
    "    p = re.compile(exp)\n",
    "    return len(p.findall(str_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html symbol\n",
    "def remove_html(str_):\n",
    "    return re.sub(\"[^A-Za-z0-9 ]\\w+;\", ' ', str_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary punctuations\n",
    "(remove ones except #,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary punctuations \n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "table_ = str.maketrans('', '', '#[]')\n",
    "punctuations = punctuations.translate(table_) + '�'\n",
    "\n",
    "def remove_punctuations(str_, punctuations):\n",
    "    table_ = str.maketrans('', '', punctuations)\n",
    "    return str_.translate(table_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change brand words\n",
    "We don't want overall distribution of customer satisfaction of each company to affect our analysis so I'll remove some of the specific words for popular brands. Let's change these words to 'gn' (remove when tokenized, but CFG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brandwords(str_):\n",
    "    p = '''#?(iphone|ipad|sxsw|hcsm|google|apple|cisco|\n",
    "    atari|intel|mac|pc|blackberry|android)[a-z0-9]*'''\n",
    "    return re.sub(p, 'gn', str_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "Define stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "sw += string.punctuation\n",
    "sw += string.digits\n",
    "sw += 'gn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_text(df0, punctuations, stopwords):\n",
    "    df = df0.copy()\n",
    "    df['upper_count'] = df.tweet.apply(lambda x: count_upper(x))\n",
    "    df['tweet'] = df.tweet.apply(lambda x: x.lower())\n",
    "    df['tweet'] = df.tweet.apply(replace_links)\n",
    "    df['tweet'] = df.tweet.apply(lambda x: remove_html(x))    \n",
    "    df['tweet'] = df.tweet.apply(lambda x: change_brandwords(x))    \n",
    "    df['mention_count'] = df.tweet.apply(lambda x: count_exp(x, '@\\w+'))\n",
    "    df['link_count'] = df.tweet.apply(lambda x: count_exp(x, '{link}')) \n",
    "    df['tag_count'] = df.tweet.apply(lambda x: count_exp(x, '#\\w+'))\n",
    "    df['exclam_count'] = df.tweet.apply(lambda x: count_exp(x, '!'))\n",
    "    df['quest_count'] = df.tweet.apply(lambda x: count_exp(x, '\\?'))\n",
    "    df['period_count'] = df.tweet.apply(lambda x: count_exp(x, '\\.'))\n",
    "    df['tag_count'] = df.tweet.apply(lambda x: count_exp(x, '#\\w+'))\n",
    "    df['tweet'] = df.tweet.apply(lambda x: remove_punctuations(x, punctuations))    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = prepro_text(X_train, punctuations, sw)\n",
    "X_val_pp = prepro_text(X_val, punctuations, sw)\n",
    "X_test_pp = prepro_text(X_test, punctuations, sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-48a9d80e3419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# combining with target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_pp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_pp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# combining with target \n",
    "train_pp = X_train_pp.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now tokenize and remove stopwords\n",
    "def tokenize(str_, stopwords):\n",
    "    return [x for x in word_tokenize(str_) if x not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp['tweet'] = train_pp.tweet.apply(lambda x: tokenize(x, sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative vs. Positve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_text = np.sum(train_pp[train_pp.sentiment == 'Negative emotion']['tweet'])\n",
    "pos_text = np.sum(train_pp[train_pp.sentiment == 'Positive emotion']['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30_neg = dict(Counter(neg_text).most_common(30))\n",
    "top30_pos = dict(Counter(pos_text).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(top30_neg.keys(), top30_neg.values())\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('negative emotion top 30 frequent words')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(top30_pos.keys(), top30_pos.values())\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('positive emotion top 30 frequent words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df = 2, stop_words = sw)\n",
    "tf_X_train = tf.fit_transform(X_train_pp['tweet'])\n",
    "tf_X_val = tf.transform(X_val_pp['tweet'])\n",
    "tf_X_test = tf.transform(X_test_pp['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_X_train = pd.DataFrame(tf_X_train.todense(), index=X_train_pp.index)\n",
    "tf_X_val = pd.DataFrame(tf_X_val.todense(), index=X_val_pp.index)\n",
    "tf_X_test = pd.DataFrame(tf_X_test.todense(), index=X_test_pp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fin = X_train_pp.join(tf_X_train)\n",
    "X_val_fin = X_val_pp.join(tf_X_val)\n",
    "X_test_fin = X_test_pp.join(tf_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Pickles\n",
    "Export preprocessed data out as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.mkdir('PKL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fin.to_pickle('PKL/X_train_fin.pkl')\n",
    "X_val_fin.to_pickle('PKL/X_val_fin.pkl')\n",
    "X_test_fin.to_pickle('PKL/X_test_fin.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
